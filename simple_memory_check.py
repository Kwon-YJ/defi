#!/usr/bin/env python3
"""
Simple Memory Leak and Performance Check
psutil ì—†ì´ë„ ì‘ë™í•˜ëŠ” ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë° ì„±ëŠ¥ ì ê²€

ë‚´ì¥ ëª¨ë“ˆë§Œ ì‚¬ìš©í•˜ì—¬ DeFi ì‹œìŠ¤í…œì˜ ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ìƒíƒœë¥¼ ì ê²€
"""

import asyncio
import gc
import json
import logging
import os
import resource
import sys
import time
import tracemalloc
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import threading
from collections import deque
import random

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SimpleMemorySnapshot:
    timestamp: datetime
    memory_usage_mb: float
    peak_memory_mb: float
    object_count: int
    garbage_count: int
    thread_count: int

@dataclass
class SimplePerformanceMetric:
    timestamp: datetime
    operation_name: str
    execution_time: float
    memory_before: float
    memory_after: float
    memory_delta: float
    success: bool

class SimpleMemoryChecker:
    """ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì ê²€ê¸° (psutil ë¶ˆí•„ìš”)"""
    
    def __init__(self, check_interval: int = 30):
        self.check_interval = check_interval
        self.snapshots = deque(maxlen=50)
        self.performance_metrics = deque(maxlen=500)
        self.is_monitoring = False
        self.monitor_thread = None
        
        # íŠ¸ë ˆì´ìŠ¤ ë©”ëª¨ë¦¬ ì‹œì‘
        tracemalloc.start()
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ì •ë³´
        self.initial_memory = self._get_memory_usage()
        
    def _get_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        try:
            # resource ëª¨ë“ˆ ì‚¬ìš© (Unix ê³„ì—´)
            if hasattr(resource, 'RUSAGE_SELF'):
                usage = resource.getrusage(resource.RUSAGE_SELF)
                # Linuxì—ì„œëŠ” KB ë‹¨ìœ„, macOSì—ì„œëŠ” bytes ë‹¨ìœ„
                if sys.platform == 'darwin':
                    return usage.ru_maxrss / 1024 / 1024  # bytes to MB
                else:
                    return usage.ru_maxrss / 1024  # KB to MB
        except:
            pass
            
        # tracemalloc ì‚¬ìš© (fallback)
        try:
            current, peak = tracemalloc.get_traced_memory()
            return current / 1024 / 1024  # bytes to MB
        except:
            return 0.0
    
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.is_monitoring:
            logger.warning("ì´ë¯¸ ëª¨ë‹ˆí„°ë§ ì¤‘ì…ë‹ˆë‹¤.")
            return
            
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        logger.info("ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=3)
        logger.info("ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _monitor_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.is_monitoring:
            try:
                snapshot = self._take_snapshot()
                self.snapshots.append(snapshot)
                
                # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì²´í¬
                if len(self.snapshots) >= 3:
                    self._check_memory_trend()
                
                time.sleep(self.check_interval)
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                time.sleep(self.check_interval)
    
    def _take_snapshot(self) -> SimpleMemorySnapshot:
        """ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ìƒì„±"""
        try:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory_usage = self._get_memory_usage()
            
            # tracemallocì—ì„œ peak memory
            try:
                current_trace, peak_trace = tracemalloc.get_traced_memory()
                peak_memory = peak_trace / 1024 / 1024  # MB
            except:
                peak_memory = memory_usage
            
            # ê°€ë¹„ì§€ ìˆ˜ì§‘
            gc.collect()
            object_count = len(gc.get_objects())
            garbage_count = len(gc.garbage)
            
            # ìŠ¤ë ˆë“œ ìˆ˜
            thread_count = threading.active_count()
            
            return SimpleMemorySnapshot(
                timestamp=datetime.now(),
                memory_usage_mb=memory_usage,
                peak_memory_mb=peak_memory,
                object_count=object_count,
                garbage_count=garbage_count,
                thread_count=thread_count
            )
            
        except Exception as e:
            logger.error(f"ìŠ¤ëƒ…ìƒ· ìƒì„± ì˜¤ë¥˜: {e}")
            return SimpleMemorySnapshot(
                timestamp=datetime.now(),
                memory_usage_mb=0,
                peak_memory_mb=0,
                object_count=0,
                garbage_count=0,
                thread_count=0
            )
    
    def _check_memory_trend(self):
        """ë©”ëª¨ë¦¬ ì¦ê°€ ì¶”ì„¸ ì²´í¬"""
        if len(self.snapshots) < 3:
            return
            
        recent_snapshots = list(self.snapshots)[-3:]
        memory_values = [s.memory_usage_mb for s in recent_snapshots]
        
        # ì—°ì†ì ì¸ ì¦ê°€ì¸ì§€ í™•ì¸
        is_increasing = all(memory_values[i] <= memory_values[i+1] for i in range(len(memory_values)-1))
        
        if is_increasing and len(memory_values) > 1:
            increase = memory_values[-1] - memory_values[0]
            if increase > 5:  # 5MB ì´ìƒ ì¦ê°€
                logger.warning(f"âš ï¸  ë©”ëª¨ë¦¬ ì¦ê°€ ê°ì§€: +{increase:.2f}MB")
                logger.warning(f"ë©”ëª¨ë¦¬: {memory_values[0]:.1f} -> {memory_values[-1]:.1f} MB")
    
    def measure_performance(self, operation_name: str):
        """ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            if asyncio.iscoroutinefunction(func):
                async def async_wrapper(*args, **kwargs):
                    return await self._measure_async_performance(operation_name, func, *args, **kwargs)
                return async_wrapper
            else:
                def sync_wrapper(*args, **kwargs):
                    return self._measure_sync_performance(operation_name, func, *args, **kwargs)
                return sync_wrapper
        return decorator
    
    async def _measure_async_performance(self, operation_name: str, func, *args, **kwargs):
        """ë¹„ë™ê¸° í•¨ìˆ˜ ì„±ëŠ¥ ì¸¡ì •"""
        start_time = time.time()
        memory_before = self._get_memory_usage()
        
        success = False
        result = None
        
        try:
            result = await func(*args, **kwargs)
            success = True
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ì¸¡ì • ì¤‘ ì˜¤ë¥˜ ({operation_name}): {e}")
            raise
        
        end_time = time.time()
        memory_after = self._get_memory_usage()
        execution_time = end_time - start_time
        memory_delta = memory_after - memory_before
        
        # ë©”íŠ¸ë¦­ ê¸°ë¡
        metric = SimplePerformanceMetric(
            timestamp=datetime.now(),
            operation_name=operation_name,
            execution_time=execution_time,
            memory_before=memory_before,
            memory_after=memory_after,
            memory_delta=memory_delta,
            success=success
        )
        
        self.performance_metrics.append(metric)
        
        # ê²½ê³  ì²´í¬
        if execution_time > 6.43:  # ë…¼ë¬¸ì˜ ëª©í‘œ ì‹œê°„
            logger.warning(f"âš ï¸  ì„±ëŠ¥ ì €í•˜ ({operation_name}): {execution_time:.2f}ì´ˆ")
        
        if memory_delta > 20:  # 20MB ì´ìƒ ì¦ê°€
            logger.warning(f"âš ï¸  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸‰ì¦ ({operation_name}): +{memory_delta:.1f}MB")
        
        return result
    
    def _measure_sync_performance(self, operation_name: str, func, *args, **kwargs):
        """ë™ê¸° í•¨ìˆ˜ ì„±ëŠ¥ ì¸¡ì •"""
        start_time = time.time()
        memory_before = self._get_memory_usage()
        
        success = False
        result = None
        
        try:
            result = func(*args, **kwargs)
            success = True
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ì¸¡ì • ì¤‘ ì˜¤ë¥˜ ({operation_name}): {e}")
            raise
        
        end_time = time.time()
        memory_after = self._get_memory_usage()
        execution_time = end_time - start_time
        memory_delta = memory_after - memory_before
        
        # ë©”íŠ¸ë¦­ ê¸°ë¡
        metric = SimplePerformanceMetric(
            timestamp=datetime.now(),
            operation_name=operation_name,
            execution_time=execution_time,
            memory_before=memory_before,
            memory_after=memory_after,
            memory_delta=memory_delta,
            success=success
        )
        
        self.performance_metrics.append(metric)
        
        # ê²½ê³  ì²´í¬
        if execution_time > 6.43:  # ë…¼ë¬¸ì˜ ëª©í‘œ ì‹œê°„
            logger.warning(f"âš ï¸  ì„±ëŠ¥ ì €í•˜ ({operation_name}): {execution_time:.2f}ì´ˆ")
        
        if memory_delta > 20:  # 20MB ì´ìƒ ì¦ê°€
            logger.warning(f"âš ï¸  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸‰ì¦ ({operation_name}): +{memory_delta:.1f}MB")
        
        return result
    
    def generate_report(self) -> Dict:
        """ê°„ë‹¨í•œ ë³´ê³ ì„œ ìƒì„±"""
        now = datetime.now()
        
        # ë©”ëª¨ë¦¬ ë¶„ì„
        memory_analysis = self._analyze_memory()
        
        # ì„±ëŠ¥ ë¶„ì„
        performance_analysis = self._analyze_performance()
        
        # ì‹œìŠ¤í…œ ì •ë³´
        system_info = {
            'python_version': sys.version.split()[0],
            'platform': sys.platform,
            'process_id': os.getpid(),
            'initial_memory_mb': self.initial_memory,
            'current_memory_mb': self._get_memory_usage(),
            'memory_growth_mb': self._get_memory_usage() - self.initial_memory,
            'total_snapshots': len(self.snapshots),
            'total_metrics': len(self.performance_metrics)
        }
        
        return {
            'report_metadata': {
                'generated_at': now.isoformat(),
                'report_type': 'simple_memory_performance_check',
                'monitoring_active': self.is_monitoring
            },
            'system_info': system_info,
            'memory_analysis': memory_analysis,
            'performance_analysis': performance_analysis,
            'recommendations': self._generate_recommendations(memory_analysis, performance_analysis)
        }
    
    def _analyze_memory(self) -> Dict:
        """ë©”ëª¨ë¦¬ ë¶„ì„"""
        if not self.snapshots:
            return {'error': 'No memory snapshots available'}
        
        snapshots_list = list(self.snapshots)
        memory_values = [s.memory_usage_mb for s in snapshots_list]
        object_counts = [s.object_count for s in snapshots_list]
        
        # ê¸°ë³¸ í†µê³„
        analysis = {
            'memory_usage': {
                'min_mb': min(memory_values) if memory_values else 0,
                'max_mb': max(memory_values) if memory_values else 0,
                'avg_mb': sum(memory_values) / len(memory_values) if memory_values else 0,
                'current_mb': memory_values[-1] if memory_values else 0,
                'trend': self._calculate_trend(memory_values)
            },
            'object_count': {
                'min': min(object_counts) if object_counts else 0,
                'max': max(object_counts) if object_counts else 0,
                'avg': sum(object_counts) / len(object_counts) if object_counts else 0,
                'current': object_counts[-1] if object_counts else 0,
                'trend': self._calculate_trend(object_counts)
            }
        }
        
        # ìœ„í—˜ë„ í‰ê°€
        analysis['risk_assessment'] = self._assess_risk(analysis)
        
        return analysis
    
    def _analyze_performance(self) -> Dict:
        """ì„±ëŠ¥ ë¶„ì„"""
        if not self.performance_metrics:
            return {'error': 'No performance metrics available'}
        
        metrics_list = list(self.performance_metrics)
        
        # ì—°ì‚°ë³„ ê·¸ë£¹í™”
        operations = {}
        for metric in metrics_list:
            op_name = metric.operation_name
            if op_name not in operations:
                operations[op_name] = []
            operations[op_name].append(metric)
        
        # ì—°ì‚°ë³„ ë¶„ì„
        operation_analysis = {}
        for op_name, op_metrics in operations.items():
            exec_times = [m.execution_time for m in op_metrics]
            memory_deltas = [m.memory_delta for m in op_metrics]
            success_count = len([m for m in op_metrics if m.success])
            
            operation_analysis[op_name] = {
                'total_calls': len(op_metrics),
                'success_rate': success_count / len(op_metrics) if op_metrics else 0,
                'avg_execution_time': sum(exec_times) / len(exec_times) if exec_times else 0,
                'max_execution_time': max(exec_times) if exec_times else 0,
                'avg_memory_impact': sum(memory_deltas) / len(memory_deltas) if memory_deltas else 0,
                'max_memory_impact': max(memory_deltas) if memory_deltas else 0
            }
        
        # ì „ì²´ ìš”ì•½
        all_exec_times = [m.execution_time for m in metrics_list]
        all_memory_deltas = [m.memory_delta for m in metrics_list]
        total_success = len([m for m in metrics_list if m.success])
        
        analysis = {
            'overall': {
                'total_operations': len(metrics_list),
                'success_rate': total_success / len(metrics_list) if metrics_list else 0,
                'avg_execution_time': sum(all_exec_times) / len(all_exec_times) if all_exec_times else 0,
                'avg_memory_impact': sum(all_memory_deltas) / len(all_memory_deltas) if all_memory_deltas else 0
            },
            'by_operation': operation_analysis,
            'performance_issues': self._identify_issues(operation_analysis)
        }
        
        return analysis
    
    def _calculate_trend(self, values: List[float]) -> str:
        """ì¶”ì„¸ ê³„ì‚°"""
        if len(values) < 2:
            return 'insufficient_data'
        
        # ê°„ë‹¨í•œ ì¶”ì„¸ ê³„ì‚°
        increases = 0
        decreases = 0
        
        for i in range(1, len(values)):
            if values[i] > values[i-1]:
                increases += 1
            elif values[i] < values[i-1]:
                decreases += 1
        
        if increases > decreases * 1.5:
            return 'increasing'
        elif decreases > increases * 1.5:
            return 'decreasing'
        else:
            return 'stable'
    
    def _assess_risk(self, memory_analysis: Dict) -> Dict:
        """ìœ„í—˜ë„ í‰ê°€"""
        risk_score = 0
        risk_factors = []
        
        memory_usage = memory_analysis.get('memory_usage', {})
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ ì¶”ì„¸
        if memory_usage.get('trend') == 'increasing':
            risk_score += 3
            risk_factors.append('Memory usage is increasing')
        
        # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        current_memory = memory_usage.get('current_mb', 0)
        if current_memory > 500:  # 500MB ì´ìƒ
            risk_score += 2
            risk_factors.append(f'High memory usage: {current_memory:.1f}MB')
        
        # ë©”ëª¨ë¦¬ ì„±ì¥ë¥ 
        max_memory = memory_usage.get('max_mb', 0)
        min_memory = memory_usage.get('min_mb', 0)
        if min_memory > 0:
            growth_ratio = (max_memory - min_memory) / min_memory
            if growth_ratio > 0.3:  # 30% ì´ìƒ ì¦ê°€
                risk_score += 2
                risk_factors.append(f'Memory grew by {growth_ratio:.1%}')
        
        # ìœ„í—˜ë„ ë ˆë²¨
        if risk_score >= 6:
            risk_level = 'HIGH'
        elif risk_score >= 3:
            risk_level = 'MEDIUM'
        elif risk_score >= 1:
            risk_level = 'LOW'
        else:
            risk_level = 'MINIMAL'
        
        return {
            'risk_level': risk_level,
            'risk_score': risk_score,
            'risk_factors': risk_factors
        }
    
    def _identify_issues(self, operation_analysis: Dict) -> List[str]:
        """ì„±ëŠ¥ ë¬¸ì œ ì‹ë³„"""
        issues = []
        
        for op_name, analysis in operation_analysis.items():
            # ì‹¤í–‰ ì‹œê°„ ë¬¸ì œ
            avg_time = analysis.get('avg_execution_time', 0)
            if avg_time > 6.43:  # ë…¼ë¬¸ ëª©í‘œ
                issues.append(f'{op_name}: Slow execution ({avg_time:.2f}s > 6.43s target)')
            
            # ì„±ê³µë¥  ë¬¸ì œ
            success_rate = analysis.get('success_rate', 0)
            if success_rate < 0.9:
                issues.append(f'{op_name}: Low success rate ({success_rate:.1%})')
            
            # ë©”ëª¨ë¦¬ ë¬¸ì œ
            avg_memory = analysis.get('avg_memory_impact', 0)
            if avg_memory > 10:  # 10MB ì´ìƒ
                issues.append(f'{op_name}: High memory impact (+{avg_memory:.1f}MB)')
        
        return issues
    
    def _generate_recommendations(self, memory_analysis: Dict, performance_analysis: Dict) -> List[str]:
        """ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë©”ëª¨ë¦¬ ê´€ë ¨
        risk_level = memory_analysis.get('risk_assessment', {}).get('risk_level', 'UNKNOWN')
        if risk_level in ['HIGH', 'MEDIUM']:
            recommendations.append('Consider implementing regular garbage collection')
            recommendations.append('Review memory-intensive operations')
            
        # ì„±ëŠ¥ ê´€ë ¨
        issues = performance_analysis.get('performance_issues', [])
        if issues:
            recommendations.append('Optimize slow operations identified in performance issues')
            recommendations.append('Consider caching for repeated operations')
        
        # ì¼ë°˜ì ì¸ ê¶Œê³ 
        if not recommendations:
            recommendations.append('System performance appears normal')
        else:
            recommendations.append('Monitor system regularly during high-load periods')
        
        return recommendations

class DeFiSimpleChecker:
    """DeFi ì‹œìŠ¤í…œ ê°„ë‹¨ ì ê²€ê¸°"""
    
    def __init__(self):
        self.checker = SimpleMemoryChecker(check_interval=20)  # 20ì´ˆë§ˆë‹¤ ì²´í¬
    
    async def run_check(self) -> str:
        """ì ê²€ ì‹¤í–‰"""
        logger.info("ğŸ” DeFi ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ì ê²€ ì‹œì‘")
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.checker.start_monitoring()
        
        try:
            # DeFi ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            await self._simulate_defi_work()
            
            # ëŒ€ê¸° ì‹œê°„ (íŒ¨í„´ ê´€ì°°)
            logger.info("â³ ë©”ëª¨ë¦¬ íŒ¨í„´ ê´€ì°°ì„ ìœ„í•´ 90ì´ˆ ëŒ€ê¸°...")
            await asyncio.sleep(90)
            
            # ë³´ê³ ì„œ ìƒì„±
            report = self.checker.generate_report()
            
            # ë³´ê³ ì„œ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_filename = f"simple_memory_check_{timestamp}.json"
            
            with open(report_filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            # ê²°ê³¼ ì¶œë ¥
            self._print_results(report)
            
            return report_filename
            
        finally:
            self.checker.stop_monitoring()
    
    async def _simulate_defi_work(self):
        """DeFi ì‘ì—… ì‹œë®¬ë ˆì´ì…˜"""
        
        # 1. ë°ì´í„° ìˆ˜ì§‘
        await self._simulate_data_collection()
        
        # 2. ê·¸ë˜í”„ ë¹Œë”©
        await self._simulate_graph_building()
        
        # 3. ì•„ë¹„íŠ¸ë˜ì§€ íƒì§€
        await self._simulate_arbitrage_detection()
        
        # 4. ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—…
        await self._simulate_intensive_work()
    
    async def _simulate_data_collection(self):
        """ë°ì´í„° ìˆ˜ì§‘ ì‹œë®¬ë ˆì´ì…˜"""
        @self.checker.measure_performance("data_collection")
        async def collect_data():
            logger.info("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì‹œë®¬ë ˆì´ì…˜...")
            data = []
            
            # 96ê°œ í”„ë¡œí† ì½œ * 25ê°œ ìì‚° ë°ì´í„°
            for protocol in range(96):
                for asset in range(25):
                    data.append({
                        'protocol': f'protocol_{protocol}',
                        'asset': f'asset_{asset}',
                        'price': random.uniform(1, 1000),
                        'liquidity': random.uniform(10000, 1000000),
                        'volume': random.uniform(1000, 100000)
                    })
            
            # ë°ì´í„° ì²˜ë¦¬
            processed = {}
            for item in data:
                key = item['protocol']
                if key not in processed:
                    processed[key] = []
                processed[key].append(item)
            
            return len(processed)
        
        result = await collect_data()
        logger.info(f"  ì™„ë£Œ: {result}ê°œ í”„ë¡œí† ì½œ ë°ì´í„° ìˆ˜ì§‘")
    
    async def _simulate_graph_building(self):
        """ê·¸ë˜í”„ ë¹Œë”© ì‹œë®¬ë ˆì´ì…˜"""
        @self.checker.measure_performance("graph_building")
        async def build_graph():
            logger.info("ğŸ•¸ï¸  ê·¸ë˜í”„ ë¹Œë”© ì‹œë®¬ë ˆì´ì…˜...")
            
            # 25ê°œ ìì‚° ë…¸ë“œ
            nodes = [f'asset_{i}' for i in range(25)]
            
            # ëª¨ë“  ìŒì— ëŒ€í•´ edge ìƒì„± (25 * 24 = 600ê°œ)
            edges = {}
            for i in range(25):
                for j in range(25):
                    if i != j:
                        key = f"{nodes[i]}_{nodes[j]}"
                        edges[key] = {
                            'weight': random.uniform(-0.1, 0.1),
                            'protocols': [f'protocol_{k}' for k in range(random.randint(1, 5))]
                        }
            
            # ì¸ì ‘ í–‰ë ¬ ê³„ì‚°
            matrix = [[0.0 for _ in range(25)] for _ in range(25)]
            for i in range(25):
                for j in range(25):
                    if i != j:
                        matrix[i][j] = random.uniform(-0.5, 0.5)
            
            return len(edges)
        
        result = await build_graph()
        logger.info(f"  ì™„ë£Œ: {result}ê°œ ì—£ì§€ ìƒì„±")
    
    async def _simulate_arbitrage_detection(self):
        """ì•„ë¹„íŠ¸ë˜ì§€ íƒì§€ ì‹œë®¬ë ˆì´ì…˜"""
        @self.checker.measure_performance("arbitrage_detection")
        async def detect_arbitrage():
            logger.info("ğŸ” ì•„ë¹„íŠ¸ë˜ì§€ íƒì§€ ì‹œë®¬ë ˆì´ì…˜...")
            
            opportunities = []
            
            # Bellman-Ford ì•Œê³ ë¦¬ì¦˜ ì‹œë®¬ë ˆì´ì…˜
            for cycle in range(50):
                path_length = random.randint(3, 6)
                path = []
                
                for step in range(path_length):
                    path.append({
                        'from': f'asset_{step % 25}',
                        'to': f'asset_{(step + 1) % 25}',
                        'rate': random.uniform(0.95, 1.05),
                        'protocol': f'protocol_{step % 96}'
                    })
                
                # ìˆ˜ìµì„± ê³„ì‚°
                total_rate = 1.0
                for step in path:
                    total_rate *= step['rate']
                
                profit = total_rate - 1.0
                if profit > 0.001:  # 0.1% ì´ìƒ ìˆ˜ìµ
                    opportunities.append({
                        'path': path,
                        'profit': profit,
                        'confidence': random.uniform(0.7, 0.95)
                    })
            
            return len(opportunities)
        
        result = await detect_arbitrage()
        logger.info(f"  ì™„ë£Œ: {result}ê°œ ê¸°íšŒ ë°œê²¬")
    
    async def _simulate_intensive_work(self):
        """ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—…"""
        @self.checker.measure_performance("intensive_operation")
        async def intensive_work():
            logger.info("ğŸ’¾ ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜...")
            
            # í° ë°ì´í„° êµ¬ì¡° ìƒì„±
            large_data = []
            
            # 96 í”„ë¡œí† ì½œ * 25 ìì‚° * 100 ì¼ = 240,000 ë°ì´í„° í¬ì¸íŠ¸
            for protocol in range(96):
                for asset in range(25):
                    for day in range(100):
                        large_data.append({
                            'protocol': protocol,
                            'asset': asset,
                            'day': day,
                            'price_history': [random.uniform(1, 100) for _ in range(24)],  # ì‹œê°„ë‹¹ ê°€ê²©
                            'volume_history': [random.uniform(100, 10000) for _ in range(24)]
                        })
            
            # ë°ì´í„° ì§‘ê³„
            aggregated = {}
            for item in large_data:
                key = f"{item['protocol']}_{item['asset']}"
                if key not in aggregated:
                    aggregated[key] = {
                        'total_volume': 0,
                        'avg_price': 0,
                        'days': 0
                    }
                
                aggregated[key]['total_volume'] += sum(item['volume_history'])
                aggregated[key]['avg_price'] += sum(item['price_history']) / len(item['price_history'])
                aggregated[key]['days'] += 1
            
            # í‰ê·  ê³„ì‚°
            for key, data in aggregated.items():
                if data['days'] > 0:
                    data['avg_price'] /= data['days']
            
            return len(aggregated)
        
        result = await intensive_work()
        logger.info(f"  ì™„ë£Œ: {result}ê°œ ì§‘ê³„ ë°ì´í„° ìƒì„±")
    
    def _print_results(self, report: Dict):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ” DeFi ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ì ê²€ ê²°ê³¼")
        print("="*60)
        
        # ì‹œìŠ¤í…œ ì •ë³´
        system_info = report.get('system_info', {})
        print(f"\nğŸ“Š ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"  Python ë²„ì „: {system_info.get('python_version', 'Unknown')}")
        print(f"  ì´ˆê¸° ë©”ëª¨ë¦¬: {system_info.get('initial_memory_mb', 0):.1f} MB")
        print(f"  í˜„ì¬ ë©”ëª¨ë¦¬: {system_info.get('current_memory_mb', 0):.1f} MB")
        print(f"  ë©”ëª¨ë¦¬ ì¦ê°€: {system_info.get('memory_growth_mb', 0):.1f} MB")
        
        # ë©”ëª¨ë¦¬ ë¶„ì„
        memory_analysis = report.get('memory_analysis', {})
        if 'risk_assessment' in memory_analysis:
            risk = memory_analysis['risk_assessment']
            print(f"\nâš ï¸  ë©”ëª¨ë¦¬ ìœ„í—˜ë„: {risk.get('risk_level', 'UNKNOWN')}")
            print(f"  ìœ„í—˜ ì ìˆ˜: {risk.get('risk_score', 0)}/7")
            
            factors = risk.get('risk_factors', [])
            if factors:
                print("  ìœ„í—˜ ìš”ì†Œ:")
                for factor in factors:
                    print(f"    â€¢ {factor}")
        
        # ì„±ëŠ¥ ë¶„ì„
        performance_analysis = report.get('performance_analysis', {})
        if 'overall' in performance_analysis:
            overall = performance_analysis['overall']
            print(f"\nğŸ“ˆ ì„±ëŠ¥ ìš”ì•½:")
            print(f"  ì „ì²´ ì—°ì‚°: {overall.get('total_operations', 0)}ê°œ")
            print(f"  ì„±ê³µë¥ : {overall.get('success_rate', 0):.1%}")
            print(f"  í‰ê·  ì‹¤í–‰ì‹œê°„: {overall.get('avg_execution_time', 0):.2f}ì´ˆ")
            print(f"  í‰ê·  ë©”ëª¨ë¦¬ ì˜í–¥: {overall.get('avg_memory_impact', 0):.1f}MB")
        
        # ì„±ëŠ¥ ë¬¸ì œ
        issues = performance_analysis.get('performance_issues', [])
        if issues:
            print(f"\nâŒ ì„±ëŠ¥ ë¬¸ì œ:")
            for issue in issues:
                print(f"    â€¢ {issue}")
        
        # ê¶Œê³ ì‚¬í•­
        recommendations = report.get('recommendations', [])
        print(f"\nğŸ’¡ ê¶Œê³ ì‚¬í•­:")
        for rec in recommendations:
            print(f"    â€¢ {rec}")
        
        print("\n" + "="*60)

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” DeFi ì‹œìŠ¤í…œ ê°„ë‹¨ ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ì ê²€")
    print("=" * 60)
    
    checker = DeFiSimpleChecker()
    
    try:
        report_file = await checker.run_check()
        print(f"\nâœ… ì ê²€ ì™„ë£Œ! ë³´ê³ ì„œ: {report_file}")
        
    except Exception as e:
        logger.error(f"ì ê²€ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"âŒ ì ê²€ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    asyncio.run(main())