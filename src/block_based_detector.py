#!/usr/bin/env python3
"""
Block-Based DeFi Arbitrage Detector
ë¸”ë¡ ê¸°ë°˜ ì‹¤ì‹œê°„ ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ì°¨ìµê±°ë˜ íƒì§€

ë…¼ë¬¸ ìš”êµ¬ì‚¬í•­ êµ¬í˜„:
- ë§¤ ë¸”ë¡ë§ˆë‹¤ ê·¸ë˜í”„ ìƒíƒœ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- 13.5ì´ˆ ë¸”ë¡ ì‹œê°„ ë‚´ 6.43ì´ˆ í‰ê·  ì‹¤í–‰ ì‹œê°„ ë‹¬ì„±
- 96ê°œ protocol actions ì²˜ë¦¬ ê°€ëŠ¥í•œ í™•ì¥ì„±
"""

import asyncio
import time
from typing import Dict, List, Optional, Callable
from datetime import datetime
from web3 import Web3
from concurrent.futures import ThreadPoolExecutor
import json

from src.market_graph import DeFiMarketGraph
from src.bellman_ford_arbitrage import BellmanFordArbitrage  
from src.real_time_collector import RealTimeDataCollector
from src.transaction_pool_monitor import TransactionPoolMonitor
from src.data_storage import DataStorage
from src.logger import setup_logger
from config.config import config
from src.performance_benchmarking import (
    start_benchmarking, end_benchmarking, time_component, 
    get_performance_report
)

logger = setup_logger(__name__)

class BlockBasedArbitrageDetector:
    """
    ë¸”ë¡ ê¸°ë°˜ ì°¨ìµê±°ë˜ íƒì§€ê¸°
    ë…¼ë¬¸ì˜ ì‹¤ì‹œê°„ ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” êµ¬í˜„
    """
    
    def __init__(self):
        self.market_graph = DeFiMarketGraph()
        self.bellman_ford = BellmanFordArbitrage(self.market_graph)
        self.real_time_collector = RealTimeDataCollector()
        self.transaction_pool_monitor = TransactionPoolMonitor()  # ìƒˆë¡œ ì¶”ê°€
        self.storage = DataStorage()
        self.w3 = Web3(Web3.HTTPProvider(config.ethereum_mainnet_rpc))
        
        # **DYNAMIC GRAPH UPDATE**: ì‹¤ì‹œê°„ ìƒíƒœ ë³€í™” ë¦¬ìŠ¤ë„ˆ ì„¤ì •
        self.market_graph.register_state_change_listener(self._on_graph_state_change)
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.execution_times = []
        self.blocks_processed = 0
        self.total_opportunities_found = 0
        
        # ì‹¤í–‰ ìƒíƒœ
        self.running = False
        self.current_block = None
        self.processing_block = False
        
        # ìŠ¤ë ˆë“œ í’€ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # ì£¼ìš” í† í°ë“¤ (ì°¨ìµê±°ë˜ ì‹œì‘ì )
        self.base_tokens = [
            "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2",  # WETH
            "0xA0b86a91c6218b36c1d19D4a2e9Eb0cE3606eB48",  # USDC
            "0x6B175474E89094C44Da98b954EedeAC495271d0F",  # DAI  
            "0xdAC17F958D2ee523a2206206994597C13D831ec7",  # USDT
        ]
        
        # DEX ì„¤ì • (96ê°œ protocol actionsë¡œ í™•ì¥ ì˜ˆì •)
        self.dex_configs = self._initialize_dex_configs()
        
        # ë©”íŠ¸ë¦­ìŠ¤
        self.metrics = {
            'total_blocks_processed': 0,
            'average_execution_time': 0.0,
            'opportunities_per_block': 0.0,
            'graph_update_time': 0.0,
            'negative_cycle_detection_time': 0.0,
            'local_search_time': 0.0,
            'blocks_within_target_time': 0,     # 6.43ì´ˆ ì´ë‚´ ì²˜ë¦¬ ë¸”ë¡ ìˆ˜
            'blocks_exceeding_target_time': 0,  # 6.43ì´ˆ ì´ˆê³¼ ì²˜ë¦¬ ë¸”ë¡ ìˆ˜
            'ethereum_block_time_violations': 0  # 13.5ì´ˆ ì´ˆê³¼ ì²˜ë¦¬ íšŸìˆ˜
        }
        
        # ë¸”ë¡ ì²˜ë¦¬ ì‹œê°„ ë³´ì¥ (ë…¼ë¬¸ ìš”êµ¬ì‚¬í•­)
        self.target_processing_time = 6.43    # ë…¼ë¬¸ ëª©í‘œ
        self.ethereum_block_time = 13.5       # Ethereum í‰ê·  ë¸”ë¡ ì‹œê°„
        self.processing_timeout = 12.0        # ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ (ì—¬ìœ  1.5ì´ˆ)
    
    def _initialize_dex_configs(self) -> List[Dict]:
        """
        DEX ì„¤ì • ì´ˆê¸°í™”
        TODO: 96ê°œ protocol actionsë¡œ í™•ì¥
        """
        return [
            {
                'name': 'uniswap_v2',
                'factory': '0x5C69bEe701ef814a2B6a3EDD4B1652CB9cc5aA6f',
                'fee': 0.003,
                'enabled': True
            },
            {
                'name': 'uniswap_v3', 
                'factory': '0x1F98431c8aD98523631AE4a59f267346ea31F984',
                'fee': 0.003,  # ê°€ë³€ ìˆ˜ìˆ˜ë£Œ
                'enabled': True
            },
            {
                'name': 'sushiswap',
                'factory': '0xC0AEe478e3658e2610c5F7A4A2E1777cE9e4f2Ac', 
                'fee': 0.003,
                'enabled': True
            },
            {
                'name': 'curve',
                'factory': None,  # Registry ê¸°ë°˜
                'fee': 0.0004,  # 0.04%
                'enabled': False  # TODO: êµ¬í˜„ ì˜ˆì •
            },
            {
                'name': 'balancer',
                'factory': '0x9424B1412450D0f8Fc2255FAf6046b98213B76Bd',
                'fee': 0.005,  # ê°€ë³€ ìˆ˜ìˆ˜ë£Œ
                'enabled': False  # TODO: êµ¬í˜„ ì˜ˆì •
            }
        ]
    
    async def start_detection(self):
        """ë¸”ë¡ ê¸°ë°˜ ì°¨ìµê±°ë˜ íƒì§€ ì‹œì‘"""
        self.running = True
        logger.info("=== ë¸”ë¡ ê¸°ë°˜ ì°¨ìµê±°ë˜ íƒì§€ ì‹œì‘ ===")
        logger.info(f"ëª©í‘œ: í‰ê·  ì‹¤í–‰ ì‹œê°„ 6.43ì´ˆ ì´ë‚´ (ë¸”ë¡ ì‹œê°„ 13.5ì´ˆ)")
        
        # WebSocket êµ¬ë… ì„¤ì •
        await self._setup_block_subscriptions()
        
        # ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ê¸° ì‹œì‘
        collection_task = asyncio.create_task(
            self.real_time_collector.start_websocket_listener()
        )
        
        # íŠ¸ëœì­ì…˜ í’€ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ë…¼ë¬¸ ìš”êµ¬ì‚¬í•­)
        txpool_task = asyncio.create_task(
            self.transaction_pool_monitor.start_monitoring()
        )
        
        # íŠ¸ëœì­ì…˜ í’€ ëª¨ë‹ˆí„°ì˜ ìƒíƒœ ë³€í™” ë¦¬ìŠ¤ë„ˆ ì—°ê²°
        self.transaction_pool_monitor.register_state_change_listener(
            self._on_mempool_state_change
        )
        
        # ë©”ì¸ íƒì§€ ë£¨í”„
        try:
            while self.running:
                await asyncio.sleep(0.1)  # ì§§ì€ ëŒ€ê¸°ë¡œ ì‘ë‹µì„± ìœ ì§€
                
        except Exception as e:
            logger.error(f"íƒì§€ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        finally:
            collection_task.cancel()
            txpool_task.cancel()
            self.executor.shutdown(wait=False)
    
    async def _setup_block_subscriptions(self):
        """ë¸”ë¡ êµ¬ë… ì„¤ì •"""
        # ìƒˆ ë¸”ë¡ êµ¬ë…
        await self.real_time_collector.subscribe_to_blocks(self._on_new_block)
        
        # Swap ì´ë²¤íŠ¸ êµ¬ë… (ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ìš©)
        await self.real_time_collector.subscribe_to_logs(self._on_swap_event)
        
        logger.info("ë¸”ë¡ ë° ì´ë²¤íŠ¸ êµ¬ë… ì„¤ì • ì™„ë£Œ")
    
    async def _on_new_block(self, block_data: Dict):
        """
        ìƒˆ ë¸”ë¡ ì²˜ë¦¬ - ë…¼ë¬¸ì˜ í•µì‹¬ ìš”êµ¬ì‚¬í•­
        ë§¤ ë¸”ë¡ë§ˆë‹¤ ì‹¤ì‹œê°„ ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ì°¨ìµê±°ë˜ íƒì§€
        """
        if self.processing_block:
            logger.warning("ì´ì „ ë¸”ë¡ ì²˜ë¦¬ ì¤‘... ìŠ¤í‚µ")
            return
        
        self.processing_block = True
        block_number = int(block_data['number'], 16)
        block_hash = block_data['hash']
        
        # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ì‹œì‘
        start_benchmarking(block_number)
        
        try:
            logger.info(f"=== ë¸”ë¡ {block_number} ì²˜ë¦¬ ì‹œì‘ (ëª©í‘œ: {self.target_processing_time}ì´ˆ) ===")
            
            # **ë…¼ë¬¸ ìš”êµ¬ì‚¬í•­**: ì²˜ë¦¬ ì‹œê°„ ì œí•œ (Ethereum ë¸”ë¡ ì‹œê°„ ë‚´ ì²˜ë¦¬ ë³´ì¥)
            processing_start_time = time.time()
            
            # íƒ€ì„ì•„ì›ƒì„ ì ìš©í•œ ì²˜ë¦¬
            try:
                opportunities_found = 0
                strategies_executed = 0
                total_revenue = 0.0
                
                # 1. ê·¸ë˜í”„ ìƒíƒœ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (ë…¼ë¬¸ ìš”êµ¬ì‚¬í•­)
                with time_component("graph_building"):
                    await asyncio.wait_for(
                        self._update_graph_state_for_block(block_number),
                        timeout=4.0  # ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ì— ìµœëŒ€ 4ì´ˆ
                    )
                    
                    # **DYNAMIC GRAPH UPDATE**: ëŒ€ê¸° ì¤‘ì¸ ì—…ë°ì´íŠ¸ë“¤ ì¦‰ì‹œ ì²˜ë¦¬
                    queued_updates = self.market_graph.process_update_queue(max_items=100)
                    if queued_updates > 0:
                        logger.debug(f"ë¸”ë¡ {block_number}: {queued_updates}ê°œ ë™ì  ì—…ë°ì´íŠ¸ ì²˜ë¦¬")
                
                # 2. ë³‘ë ¬ ì°¨ìµê±°ë˜ íƒì§€ (ê° base tokenë³„)
                with time_component("negative_cycle_detection"):
                    remaining_time = self.processing_timeout - (time.time() - processing_start_time)
                    if remaining_time > 2.0:  # ìµœì†Œ 2ì´ˆëŠ” ë‚¨ì•„ì•¼ í•¨
                        all_opportunities = await asyncio.wait_for(
                            self._parallel_arbitrage_detection(),
                            timeout=remaining_time - 1.0
                        )
                        opportunities_found = len(all_opportunities)
                    else:
                        logger.warning(f"ë¸”ë¡ {block_number}: ì‹œê°„ ë¶€ì¡±ìœ¼ë¡œ íƒì§€ ìŠ¤í‚µ")
                        all_opportunities = []
                
                # 3. ê¸°íšŒ ì²˜ë¦¬ ë° ì €ì¥
                if all_opportunities:
                    remaining_time = self.processing_timeout - (time.time() - processing_start_time)
                    if remaining_time > 1.0:
                        with time_component("validation"):
                            strategies_executed, total_revenue = await asyncio.wait_for(
                                self._process_block_opportunities(
                                    block_number, block_hash, all_opportunities
                                ),
                                timeout=remaining_time - 0.5
                            )
                    else:
                        logger.warning(f"ë¸”ë¡ {block_number}: ì‹œê°„ ë¶€ì¡±ìœ¼ë¡œ ì²˜ë¦¬ ìŠ¤í‚µ")
                        
            except asyncio.TimeoutError:
                processing_time = time.time() - processing_start_time
                logger.error(
                    f"ğŸš¨ ë¸”ë¡ {block_number} ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ ({processing_time:.2f}s > {self.processing_timeout}s)"
                )
                self.metrics['ethereum_block_time_violations'] += 1
                opportunities_found = 0
                strategies_executed = 0
                total_revenue = 0.0
            
            # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ì™„ë£Œ
            metrics = end_benchmarking(
                opportunities_found=opportunities_found,
                strategies_executed=strategies_executed,
                total_revenue=total_revenue,
                gas_cost=0.02  # ì˜ˆìƒ ê°€ìŠ¤ ë¹„ìš©
            )
            
            # ë…¼ë¬¸ ê¸°ì¤€ ì„±ëŠ¥ ì²´í¬
            if metrics.total_execution_time > self.target_processing_time:
                logger.warning(
                    f"âš ï¸ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼: {metrics.total_execution_time:.3f}s > {self.target_processing_time}s ëª©í‘œ"
                )
                self.metrics['blocks_exceeding_target_time'] += 1
            else:
                logger.info(
                    f"âœ… ì‹¤í–‰ ì‹œê°„ ëª©í‘œ ë‹¬ì„±: {metrics.total_execution_time:.3f}s < {self.target_processing_time}s"
                )
                self.metrics['blocks_within_target_time'] += 1
            
            # Ethereum ë¸”ë¡ ì‹œê°„ ì²´í¬
            if metrics.total_execution_time > self.ethereum_block_time:
                logger.error(
                    f"ğŸš¨ Ethereum ë¸”ë¡ ì‹œê°„ ì´ˆê³¼: {metrics.total_execution_time:.3f}s > {self.ethereum_block_time}s"
                )
                self.metrics['ethereum_block_time_violations'] += 1
            
        except Exception as e:
            logger.error(f"ë¸”ë¡ {block_number} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œì—ë„ ë²¤ì¹˜ë§ˆí‚¹ ì™„ë£Œ
            end_benchmarking(opportunities_found=0, strategies_executed=0)
        finally:
            self.processing_block = False
            self.current_block = block_number
    
    async def _update_graph_state_for_block(self, block_number: int):
        """
        ë¸”ë¡ë³„ ê·¸ë˜í”„ ìƒíƒœ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
        ë…¼ë¬¸ ìš”êµ¬ì‚¬í•­: "Graph state buildingì„ ë§¤ ë¸”ë¡ë§ˆë‹¤ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"
        """
        logger.debug(f"ë¸”ë¡ {block_number}: ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        # ë³‘ë ¬ë¡œ ê° DEXì˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        update_tasks = []
        
        for dex_config in self.dex_configs:
            if dex_config['enabled']:
                task = asyncio.create_task(
                    self._update_dex_state(dex_config, block_number)
                )
                update_tasks.append(task)
        
        # ëª¨ë“  DEX ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ ëŒ€ê¸°
        if update_tasks:
            await asyncio.gather(*update_tasks, return_exceptions=True)
        
        # ê·¸ë˜í”„ í†µê³„ ë¡œê¹…
        stats = self.market_graph.get_graph_stats()
        logger.debug(
            f"ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {stats['nodes']}ê°œ ë…¸ë“œ, "
            f"{stats['edges']}ê°œ ì—£ì§€"
        )
    
    async def _update_dex_state(self, dex_config: Dict, block_number: int):
        """íŠ¹ì • DEXì˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        try:
            dex_name = dex_config['name']
            
            # ì£¼ìš” ê±°ë˜ ìŒë“¤ì— ëŒ€í•œ ë¦¬ì €ë¸Œ ì •ë³´ ì¡°íšŒ
            major_pairs = [
                ("WETH", "USDC"),
                ("WETH", "DAI"),
                ("WETH", "USDT"), 
                ("USDC", "DAI"),
                ("USDC", "USDT"),
                ("DAI", "USDT")
            ]
            
            for token0_symbol, token1_symbol in major_pairs:
                # TODO: ì‹¤ì œ ì˜¨ì²´ì¸ ë°ì´í„° ì¡°íšŒ êµ¬í˜„
                # pool_data = await self._get_pool_reserves(token0, token1, dex_config)
                # if pool_data:
                #     self.market_graph.add_trading_pair(
                #         token0, token1, dex_name,
                #         pool_data['address'], 
                #         pool_data['reserve0'], 
                #         pool_data['reserve1'],
                #         dex_config['fee']
                #     )
                
                # ì„ì‹œ ëª¨ì˜ ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ì‹œ ì œê±°)
                await self._add_mock_trading_pair(
                    token0_symbol, token1_symbol, dex_name, dex_config['fee']
                )
                
        except Exception as e:
            logger.error(f"DEX {dex_config['name']} ìƒíƒœ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def _add_mock_trading_pair(self, token0_symbol: str, token1_symbol: str, 
                                   dex_name: str, fee: float):
        """ëª¨ì˜ ê±°ë˜ ìŒ ì¶”ê°€ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)"""
        # í† í° ì£¼ì†Œ ë§¤í•‘
        token_addresses = {
            "WETH": "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2",
            "USDC": "0xA0b86a91c6218b36c1d19D4a2e9Eb0cE3606eB48", 
            "DAI": "0x6B175474E89094C44Da98b954EedeAC495271d0F",
            "USDT": "0xdAC17F958D2ee523a2206206994597C13D831ec7"
        }
        
        token0_addr = token_addresses.get(token0_symbol)
        token1_addr = token_addresses.get(token1_symbol)
        
        if token0_addr and token1_addr:
            # ëª¨ì˜ ë¦¬ì €ë¸Œ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ì˜¨ì²´ì¸ì—ì„œ ì¡°íšŒ)
            import random
            reserve0 = random.uniform(100, 10000)  # 100-10000 ETH
            reserve1 = random.uniform(100000, 50000000)  # 100K-50M USDC/DAI/USDT
            
            # ì‹¤ì œ í™˜ìœ¨ ë°˜ì˜ (ETH = $2000 ê¸°ì¤€)
            if token0_symbol == "WETH":
                reserve1 = reserve0 * 2000 * random.uniform(0.95, 1.05)
            
            pool_address = f"0x{hash((token0_addr, token1_addr, dex_name)) % (16**40):040x}"
            
            self.market_graph.add_trading_pair(
                token0_addr, token1_addr, dex_name,
                pool_address, reserve0, reserve1, fee
            )
    
    async def _parallel_arbitrage_detection(self) -> List:
        """ë³‘ë ¬ ì°¨ìµê±°ë˜ íƒì§€"""
        detection_tasks = []
        
        for base_token in self.base_tokens:
            task = asyncio.create_task(
                self._detect_opportunities_for_token(base_token)
            )
            detection_tasks.append(task)
        
        # ëª¨ë“  í† í°ì— ëŒ€í•œ íƒì§€ ì™„ë£Œ ëŒ€ê¸°
        results = await asyncio.gather(*detection_tasks, return_exceptions=True)
        
        # ê²°ê³¼ í†µí•©
        all_opportunities = []
        for result in results:
            if isinstance(result, list):
                all_opportunities.extend(result)
            elif isinstance(result, Exception):
                logger.error(f"ë³‘ë ¬ íƒì§€ ì˜¤ë¥˜: {result}")
        
        return all_opportunities
    
    async def _detect_opportunities_for_token(self, base_token: str) -> List:
        """íŠ¹ì • í† í°ì— ëŒ€í•œ ì°¨ìµê±°ë˜ ê¸°íšŒ íƒì§€"""
        loop = asyncio.get_event_loop()
        
        # CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        # Local searchëŠ” Bellman-Ford ë‚´ë¶€ì—ì„œ ìˆ˜í–‰ë¨
        with time_component("local_search"):
            opportunities = await loop.run_in_executor(
                self.executor,
                self.bellman_ford.find_negative_cycles,
            base_token,
            4  # max_path_length
        )
        
        return opportunities
    
    async def _process_block_opportunities(self, block_number: int, 
                                        block_hash: str, opportunities: List):
        """ë¸”ë¡ì—ì„œ ë°œê²¬ëœ ê¸°íšŒë“¤ ì²˜ë¦¬"""
        logger.info(
            f"ë¸”ë¡ {block_number}: {len(opportunities)}ê°œ ì°¨ìµê±°ë˜ ê¸°íšŒ ë°œê²¬"
        )
        
        total_revenue = 0
        processed_count = 0
        
        for opp in opportunities:
            if opp.net_profit > 0.001:  # ìµœì†Œ ìˆ˜ìµ ì„ê³„ê°’
                # ê¸°íšŒ ì •ë³´ ë¡œê¹…
                logger.info(
                    f"  ê¸°íšŒ: {' -> '.join(opp.path)} "
                    f"ìˆ˜ìµ: {opp.net_profit:.6f} ETH "
                    f"ì‹ ë¢°ë„: {opp.confidence:.2f}"
                )
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                await self.storage.store_arbitrage_opportunity({
                    'block_number': block_number,
                    'block_hash': block_hash,
                    'timestamp': datetime.now().isoformat(),
                    'path': opp.path,
                    'profit_ratio': opp.profit_ratio,
                    'net_profit': opp.net_profit,
                    'required_capital': opp.required_capital,
                    'confidence': opp.confidence,
                    'dexes': [edge.dex for edge in opp.edges]
                })
                
                total_revenue += opp.net_profit
                processed_count += 1
        
        if processed_count > 0:
            logger.info(
                f"ë¸”ë¡ {block_number} ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ ê¸°íšŒ, "
                f"ì´ ì˜ˆìƒ ìˆ˜ìµ: {total_revenue:.6f} ETH"
            )
        
        self.total_opportunities_found += processed_count
    
    async def _on_swap_event(self, log_data: Dict):
        """Swap ì´ë²¤íŠ¸ ì²˜ë¦¬ - ë™ì  ê·¸ë˜í”„ ìƒíƒœ ì¦‰ì‹œ ì—…ë°ì´íŠ¸"""
        try:
            pool_address = log_data['address']
            
            # **DYNAMIC GRAPH UPDATE**: íë¥¼ í†µí•œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” log_dataì—ì„œ ìƒˆë¡œìš´ ë¦¬ì €ë¸Œ ì •ë³´ë¥¼ íŒŒì‹±
            # ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ ëª¨ì˜ ë°ì´í„° ì‚¬ìš©
            import random
            mock_reserve0 = random.uniform(100, 10000)
            mock_reserve1 = random.uniform(100000, 50000000)
            
            # ë†’ì€ ìš°ì„ ìˆœìœ„ë¡œ ì—…ë°ì´íŠ¸ íì— ì¶”ê°€
            self.market_graph.queue_update('pool_update', {
                'pool_address': pool_address,
                'reserve0': mock_reserve0,
                'reserve1': mock_reserve1,
                'source': 'swap_event',
                'tx_hash': log_data.get('transactionHash')
            }, priority=1)  # ìµœê³  ìš°ì„ ìˆœìœ„
            
            logger.debug(f"ë™ì  ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ - Swap ì´ë²¤íŠ¸: {pool_address}")
            
        except Exception as e:
            logger.error(f"Swap ì´ë²¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    def _update_performance_metrics(self, total_time: float, 
                                  graph_update_time: float,
                                  detection_time: float, 
                                  opportunities_count: int):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.execution_times.append(total_time)
        self.blocks_processed += 1
        
        # ìµœê·¼ 100ë¸”ë¡ì˜ í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        recent_times = self.execution_times[-100:]
        avg_execution_time = sum(recent_times) / len(recent_times)
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.metrics.update({
            'total_blocks_processed': self.blocks_processed,
            'average_execution_time': avg_execution_time,
            'opportunities_per_block': self.total_opportunities_found / max(self.blocks_processed, 1),
            'graph_update_time': graph_update_time,
            'negative_cycle_detection_time': detection_time,
            'current_execution_time': total_time
        })
        
        # 100ë¸”ë¡ë§ˆë‹¤ ì„±ëŠ¥ ë³´ê³ 
        if self.blocks_processed % 100 == 0:
            self._log_performance_report()
    
    def _log_performance_report(self):
        """ì„±ëŠ¥ ë³´ê³ ì„œ ì¶œë ¥"""
        logger.info("=== ì„±ëŠ¥ ë³´ê³ ì„œ (ìµœê·¼ 100ë¸”ë¡) ===")
        logger.info(f"í‰ê·  ì‹¤í–‰ ì‹œê°„: {self.metrics['average_execution_time']:.3f}s")
        logger.info(f"ëª©í‘œ ëŒ€ë¹„: {self.metrics['average_execution_time']:.3f}s / 6.43s")
        logger.info(f"ë¸”ë¡ë‹¹ í‰ê·  ê¸°íšŒ: {self.metrics['opportunities_per_block']:.2f}ê°œ")
        logger.info(f"ì´ ì²˜ë¦¬ ë¸”ë¡: {self.metrics['total_blocks_processed']}ê°œ")
        logger.info(f"ì´ ë°œê²¬ ê¸°íšŒ: {self.total_opportunities_found}ê°œ")
        
        # ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
        target_achieved = self.metrics['average_execution_time'] <= 6.43
        status = "âœ… ë‹¬ì„±" if target_achieved else "âŒ ë¯¸ë‹¬ì„±"
        logger.info(f"ë…¼ë¬¸ ì„±ëŠ¥ ê¸°ì¤€: {status}")
    
    def get_metrics(self) -> Dict:
        """í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        return self.metrics.copy()
    
    async def _on_graph_state_change(self, notification: Dict):
        """
        ê·¸ë˜í”„ ìƒíƒœ ë³€í™” ë¦¬ìŠ¤ë„ˆ ì½œë°±
        ë™ì  ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ ì‹œ í˜¸ì¶œë¨
        """
        change_type = notification['type']
        change_data = notification['data']
        graph_hash = notification['graph_hash']
        
        logger.debug(f"ê·¸ë˜í”„ ìƒíƒœ ë³€í™” ê°ì§€: {change_type} (hash: {graph_hash[:8]}...)")
        
        # ìƒíƒœ ë³€í™” í†µê³„ ì—…ë°ì´íŠ¸
        if change_type == 'pool_update':
            updated_pairs = change_data.get('updated_pairs', 0)
            update_time = change_data.get('update_time', 0)
            logger.debug(f"í’€ ì—…ë°ì´íŠ¸: {updated_pairs}ê°œ ìŒ, {update_time:.3f}ì´ˆ")
            
        elif change_type == 'queue_processed':
            processed_count = change_data.get('processed_count', 0)
            logger.debug(f"ì—…ë°ì´íŠ¸ í ì²˜ë¦¬: {processed_count}ê°œ ì™„ë£Œ")
            
        elif change_type == 'auto_detection':
            if change_data.get('changed'):
                logger.info(f"ìë™ ìƒíƒœ ë³€í™” ê°ì§€: {change_data['previous_hash'][:8]} -> {change_data['current_hash'][:8]}")
    
    async def _on_mempool_state_change(self, change_data: Dict):
        """
        Mempool ìƒíƒœ ë³€í™” ë¦¬ìŠ¤ë„ˆ ì½œë°±
        íŠ¸ëœì­ì…˜ í’€ ëª¨ë‹ˆí„°ë§ì—ì„œ ê°ì§€í•œ ìƒíƒœ ë³€í™” ì²˜ë¦¬
        """
        change_type = change_data['type']
        
        if change_type == 'new_block':
            block_number = change_data['block_number']
            logger.debug(f"Mempoolì—ì„œ ìƒˆ ë¸”ë¡ ê°ì§€: {block_number}")
            
        elif change_type == 'arbitrage_detected':
            tx_hash = change_data.get('tx_hash', '')
            logger.info(f"Mempoolì—ì„œ ì°¨ìµê±°ë˜ íŠ¸ëœì­ì…˜ ê°ì§€: {tx_hash[:10]}...")
            
            # ì¦‰ì‹œ ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
            await self._trigger_immediate_graph_update(f"arbitrage_tx_{tx_hash}")
            
        elif change_type == 'mev_opportunity':
            mev_score = change_data.get('mev_score', 0)
            tx_hash = change_data.get('tx_hash', '')
            logger.info(f"MEV ê¸°íšŒ ê°ì§€ (ì ìˆ˜: {mev_score:.2f}): {tx_hash[:10]}...")
            
            # ë†’ì€ MEV ì ìˆ˜ë©´ ìš°ì„ ìˆœìœ„ ì²˜ë¦¬
            if mev_score > 0.8:
                await self._trigger_priority_processing(change_data)
    
    async def _trigger_immediate_graph_update(self, trigger_reason: str):
        """ì¦‰ì‹œ ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°"""
        try:
            logger.debug(f"ì¦‰ì‹œ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°: {trigger_reason}")
            
            # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ì—…ë°ì´íŠ¸ë“¤ ì¦‰ì‹œ ì²˜ë¦¬
            processed_updates = self.market_graph.process_update_queue(
                max_items=50, 
                priority_only=True
            )
            
            if processed_updates > 0:
                logger.info(f"ì¦‰ì‹œ ì²˜ë¦¬ëœ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸: {processed_updates}ê°œ")
                
        except Exception as e:
            logger.error(f"ì¦‰ì‹œ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def _trigger_priority_processing(self, mev_data: Dict):
        """ìš°ì„ ìˆœìœ„ ì²˜ë¦¬ íŠ¸ë¦¬ê±°"""
        try:
            tx_hash = mev_data.get('tx_hash', '')
            mev_score = mev_data.get('mev_score', 0)
            
            logger.info(f"ìš°ì„ ìˆœìœ„ MEV ì²˜ë¦¬: {tx_hash[:10]}... (ì ìˆ˜: {mev_score:.2f})")
            
            # ì—¬ê¸°ì„œ ì¦‰ì‹œ ì°¨ìµê±°ë˜ íƒì§€ ì‹¤í–‰ ê°€ëŠ¥
            # í•˜ì§€ë§Œ í˜„ì¬ ë¸”ë¡ ì²˜ë¦¬ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ
            if not self.processing_block:
                logger.info("ë¸”ë¡ ì²˜ë¦¬ ì¤‘ì´ ì•„ë‹ˆë¯€ë¡œ ì¦‰ì‹œ MEV ë¶„ì„ ì‹œì‘")
                # ì¦‰ì‹œ ë¶„ì„ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
                
        except Exception as e:
            logger.error(f"ìš°ì„ ìˆœìœ„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def stop_detection(self):
        """íƒì§€ ì¤‘ì§€"""
        self.running = False
        self.real_time_collector.stop()
        self.transaction_pool_monitor.stop_monitoring()  # íŠ¸ëœì­ì…˜ í’€ ëª¨ë‹ˆí„° ì¤‘ì§€
        self.executor.shutdown(wait=True)
        
        # ìƒíƒœ ë³€í™” ë¦¬ìŠ¤ë„ˆ í•´ì œ
        self.market_graph.remove_state_change_listener(self._on_graph_state_change)
        self.transaction_pool_monitor.remove_state_change_listener(self._on_mempool_state_change)
        
        logger.info("ë¸”ë¡ ê¸°ë°˜ ì°¨ìµê±°ë˜ íƒì§€ ì¤‘ì§€")

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    detector = BlockBasedArbitrageDetector()
    
    try:
        await detector.start_detection()
    except KeyboardInterrupt:
        detector.stop_detection()
        logger.info("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())