"""
Historical Data Backfilling Module
TODO requirement completion: Historical data backfilling for analysis

ì´ ëª¨ë“ˆì€ ë…¼ë¬¸ [2103.02228]ì˜ DeFiPoser-ARB ì‹œìŠ¤í…œ ì¬í˜„ì„ ìœ„í•œ
ê³¼ê±° ë°ì´í„° ë°±í•„ë§ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.

Features:
- Historical price data collection from multiple sources
- Block-by-block historical data reconstruction
- Data gap filling and interpolation
- Historical arbitrage opportunity analysis
- Performance analysis over 150 days (paper requirement)
"""

import asyncio
import aiohttp
import json
import time
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
import sqlite3
from web3 import Web3

from src.logger import setup_logger
from src.token_manager import TokenManager
from src.real_time_price_feeds import PriceFeed
from config.config import config

logger = setup_logger(__name__)

@dataclass
class HistoricalPricePoint:
    """ê³¼ê±° ê°€ê²© ë°ì´í„° í¬ì¸íŠ¸"""
    token_address: str
    symbol: str
    price_usd: float
    timestamp: int
    block_number: int
    source: str
    volume_24h: float = 0.0
    market_cap: float = 0.0

@dataclass
class BlockData:
    """ë¸”ë¡ ë°ì´í„°"""
    number: int
    timestamp: int
    hash: str
    prices: Dict[str, HistoricalPricePoint]

class HistoricalDataBackfill:
    """
    ê³¼ê±° ë°ì´í„° ë°±í•„ë§ ê´€ë¦¬ì
    
    ë…¼ë¬¸ì˜ 150ì¼ê°„ ë¶„ì„ì„ ìœ„í•œ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬
    ë¸”ë¡ 9,100,000 ~ 10,050,000 êµ¬ê°„ (150ì¼) ë°ì´í„° ì¬í˜„
    """
    
    def __init__(self, token_manager: Optional[TokenManager] = None):
        self.token_manager = token_manager or TokenManager()
        self.db_path = "historical_data.db"
        
        # ë…¼ë¬¸ì˜ ë¶„ì„ êµ¬ê°„ (150ì¼)
        self.start_block = 9_100_000
        self.end_block = 10_050_000
        self.total_blocks = self.end_block - self.start_block
        
        # ë°ì´í„° ì†ŒìŠ¤ë“¤
        self.data_sources = {
            'coingecko': 'https://api.coingecko.com/api/v3',
            'cryptocompare': 'https://min-api.cryptocompare.com/data',
            'coinmarketcap': 'https://pro-api.coinmarketcap.com/v1'
        }
        
        # Web3 ì—°ê²°
        if hasattr(config, 'ethereum_mainnet_rpc') and config.ethereum_mainnet_rpc:
            self.w3 = Web3(Web3.HTTPProvider(config.ethereum_mainnet_rpc))
        else:
            self.w3 = None
            logger.warning("Web3 ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
        # DB ì´ˆê¸°í™”
        self._init_database()
        
    def _init_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ê°€ê²© ë°ì´í„° í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS historical_prices (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    token_address TEXT NOT NULL,
                    symbol TEXT NOT NULL,
                    price_usd REAL NOT NULL,
                    timestamp INTEGER NOT NULL,
                    block_number INTEGER NOT NULL,
                    source TEXT NOT NULL,
                    volume_24h REAL DEFAULT 0,
                    market_cap REAL DEFAULT 0,
                    UNIQUE(token_address, block_number, source)
                )
            ''')
            
            # ë¸”ë¡ ë°ì´í„° í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS blocks (
                    number INTEGER PRIMARY KEY,
                    timestamp INTEGER NOT NULL,
                    hash TEXT NOT NULL,
                    processed BOOLEAN DEFAULT FALSE
                )
            ''')
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_prices_block ON historical_prices(block_number)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_prices_token ON historical_prices(token_address)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_prices_timestamp ON historical_prices(timestamp)')
            
            conn.commit()
            conn.close()
            
            logger.info("ê³¼ê±° ë°ì´í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
    async def start_backfill(self, start_block: Optional[int] = None, end_block: Optional[int] = None):
        """ê³¼ê±° ë°ì´í„° ë°±í•„ë§ ì‹œì‘"""
        start_block = start_block or self.start_block
        end_block = end_block or self.end_block
        
        logger.info(f"ê³¼ê±° ë°ì´í„° ë°±í•„ë§ ì‹œì‘: ë¸”ë¡ {start_block:,} ~ {end_block:,}")
        
        # 1. ë¸”ë¡ ì •ë³´ ìˆ˜ì§‘
        await self._collect_block_info(start_block, end_block)
        
        # 2. ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
        await self._collect_historical_prices(start_block, end_block)
        
        # 3. ë°ì´í„° ê²€ì¦ ë° ë³´ê°„
        await self._validate_and_interpolate(start_block, end_block)
        
        # 4. ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        await self._generate_analysis_report(start_block, end_block)
        
        logger.info("ê³¼ê±° ë°ì´í„° ë°±í•„ë§ ì™„ë£Œ")
        
    async def _collect_block_info(self, start_block: int, end_block: int):
        """ë¸”ë¡ ì •ë³´ ìˆ˜ì§‘"""
        if not self.w3 or not self.w3.is_connected():
            logger.warning("Web3 ì—°ê²°ì´ ì—†ì–´ ë¸”ë¡ ì •ë³´ ìˆ˜ì§‘ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return
            
        logger.info(f"ë¸”ë¡ ì •ë³´ ìˆ˜ì§‘: {start_block:,} ~ {end_block:,}")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì´ë¯¸ ìˆ˜ì§‘ëœ ë¸”ë¡ í™•ì¸
        cursor.execute('SELECT number FROM blocks WHERE number BETWEEN ? AND ?', 
                      (start_block, end_block))
        existing_blocks = {row[0] for row in cursor.fetchall()}
        
        # ìˆ˜ì§‘í•  ë¸”ë¡ë“¤
        blocks_to_collect = set(range(start_block, end_block + 1)) - existing_blocks
        total_blocks = len(blocks_to_collect)
        
        if not blocks_to_collect:
            logger.info("ëª¨ë“  ë¸”ë¡ ì •ë³´ê°€ ì´ë¯¸ ìˆ˜ì§‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            conn.close()
            return
            
        logger.info(f"{total_blocks:,}ê°œ ë¸”ë¡ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤")
        
        batch_size = 100
        processed = 0
        
        for i in range(0, len(blocks_to_collect), batch_size):
            batch = list(blocks_to_collect)[i:i + batch_size]
            
            try:
                # ë³‘ë ¬ë¡œ ë¸”ë¡ ì •ë³´ ìˆ˜ì§‘
                tasks = [self._get_block_info(block_num) for block_num in batch]
                block_infos = await asyncio.gather(*tasks, return_exceptions=True)
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                block_data = []
                for block_num, block_info in zip(batch, block_infos):
                    if isinstance(block_info, Exception):
                        logger.error(f"ë¸”ë¡ {block_num} ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {block_info}")
                        continue
                        
                    if block_info:
                        block_data.append((
                            block_info['number'],
                            block_info['timestamp'], 
                            block_info['hash'],
                            False
                        ))
                        
                if block_data:
                    cursor.executemany(
                        'INSERT OR REPLACE INTO blocks (number, timestamp, hash, processed) VALUES (?, ?, ?, ?)',
                        block_data
                    )
                    conn.commit()
                    
                processed += len(batch)
                if processed % 1000 == 0:
                    progress = (processed / total_blocks) * 100
                    logger.info(f"ë¸”ë¡ ì •ë³´ ìˆ˜ì§‘ ì§„í–‰ë¥ : {processed:,}/{total_blocks:,} ({progress:.1f}%)")
                    
            except Exception as e:
                logger.error(f"ë¸”ë¡ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                
        conn.close()
        logger.info(f"ë¸”ë¡ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {processed:,}ê°œ ë¸”ë¡")
        
    async def _get_block_info(self, block_number: int) -> Optional[Dict]:
        """ê°œë³„ ë¸”ë¡ ì •ë³´ ì¡°íšŒ"""
        try:
            block = self.w3.eth.get_block(block_number, full_transactions=False)
            return {
                'number': block.number,
                'timestamp': block.timestamp,
                'hash': block.hash.hex()
            }
        except Exception as e:
            logger.debug(f"ë¸”ë¡ {block_number} ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
            
    async def _collect_historical_prices(self, start_block: int, end_block: int):
        """ê³¼ê±° ê°€ê²© ë°ì´í„° ìˆ˜ì§‘"""
        logger.info("ê³¼ê±° ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        # ë¸”ë¡ íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°íšŒ
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT number, timestamp FROM blocks 
            WHERE number BETWEEN ? AND ? 
            ORDER BY number
        ''', (start_block, end_block))
        
        block_timestamps = dict(cursor.fetchall())
        conn.close()
        
        if not block_timestamps:
            logger.warning("ë¸”ë¡ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¸”ë¡ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
            return
            
        logger.info(f"{len(block_timestamps):,}ê°œ ë¸”ë¡ì— ëŒ€í•œ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘")
        
        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™” (API íš¨ìœ¨ì„±ì„ ìœ„í•´)
        daily_blocks = {}
        for block_num, timestamp in block_timestamps.items():
            date_key = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
            if date_key not in daily_blocks:
                daily_blocks[date_key] = []
            daily_blocks[date_key].append((block_num, timestamp))
            
        logger.info(f"{len(daily_blocks)}ì¼ì¹˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤")
        
        # ì¼ë³„ë¡œ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
        for date_str, blocks in daily_blocks.items():
            try:
                await self._collect_daily_prices(date_str, blocks)
                await asyncio.sleep(1)  # API rate limiting
            except Exception as e:
                logger.error(f"{date_str} ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                
    async def _collect_daily_prices(self, date_str: str, blocks: List[Tuple[int, int]]):
        """ì¼ë³„ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # CoinGeckoì—ì„œ ì¼ë³„ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
            date_obj = datetime.strptime(date_str, '%Y-%m-%d')
            
            # ì£¼ìš” í† í°ë“¤ì˜ CoinGecko ID ìˆ˜ì§‘
            token_ids = []
            token_map = {}  # coingecko_id -> token_address
            
            for address, token in self.token_manager.tokens.items():
                if token.coingecko_id:
                    token_ids.append(token.coingecko_id)
                    token_map[token.coingecko_id] = address
                    
            if not token_ids:
                return
                
            # CoinGecko API í˜¸ì¶œ
            url = f"{self.data_sources['coingecko']}/coins/{token_ids[0]}/history"
            params = {
                'date': date_obj.strftime('%d-%m-%Y'),
                'localization': 'false'
            }
            
            price_data = {}
            
            # ê° í† í°ë³„ë¡œ ê°€ê²© ìˆ˜ì§‘ (ë°°ì¹˜ APIê°€ ì—†ì–´ì„œ ê°œë³„ í˜¸ì¶œ)
            for i, token_id in enumerate(token_ids[:20]):  # API ì œí•œìœ¼ë¡œ 20ê°œë§Œ
                try:
                    url = f"{self.data_sources['coingecko']}/coins/{token_id}/history"
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                current_price = data.get('market_data', {}).get('current_price', {}).get('usd')
                                market_cap = data.get('market_data', {}).get('market_cap', {}).get('usd', 0)
                                total_volume = data.get('market_data', {}).get('total_volume', {}).get('usd', 0)
                                
                                if current_price and current_price > 0:
                                    token_address = token_map.get(token_id)
                                    if token_address:
                                        price_data[token_address] = {
                                            'price': current_price,
                                            'market_cap': market_cap,
                                            'volume': total_volume
                                        }
                                        
                            elif response.status == 429:
                                logger.warning("CoinGecko rate limit reached")
                                break
                                
                    # Rate limiting
                    if i % 10 == 0 and i > 0:
                        await asyncio.sleep(2)
                        
                except Exception as e:
                    logger.debug(f"í† í° {token_id} ê°€ê²© ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    
            # ìˆ˜ì§‘ëœ ê°€ê²© ë°ì´í„°ë¥¼ ê° ë¸”ë¡ì— ì ìš©
            if price_data:
                await self._save_historical_prices(blocks, price_data, 'coingecko')
                logger.info(f"{date_str}: {len(price_data)}ê°œ í† í° ê°€ê²© ë°ì´í„° ì €ì¥")
                
        except Exception as e:
            logger.error(f"ì¼ë³„ ê°€ê²© ìˆ˜ì§‘ ì‹¤íŒ¨ {date_str}: {e}")
            
    async def _save_historical_prices(self, blocks: List[Tuple[int, int]], 
                                    price_data: Dict, source: str):
        """ê³¼ê±° ê°€ê²© ë°ì´í„° ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            price_records = []
            
            for block_num, timestamp in blocks:
                for token_address, data in price_data.items():
                    token_info = self.token_manager.tokens.get(token_address)
                    if not token_info:
                        continue
                        
                    price_records.append((
                        token_address,
                        token_info.symbol,
                        data['price'],
                        timestamp,
                        block_num,
                        source,
                        data.get('volume', 0),
                        data.get('market_cap', 0)
                    ))
                    
            if price_records:
                cursor.executemany('''
                    INSERT OR REPLACE INTO historical_prices 
                    (token_address, symbol, price_usd, timestamp, block_number, source, volume_24h, market_cap)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', price_records)
                
                conn.commit()
                
            conn.close()
            
        except Exception as e:
            logger.error(f"ê³¼ê±° ê°€ê²© ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            
    async def _validate_and_interpolate(self, start_block: int, end_block: int):
        """ë°ì´í„° ê²€ì¦ ë° ë³´ê°„"""
        logger.info("ë°ì´í„° ê²€ì¦ ë° ë³´ê°„ ì‹œì‘")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # í† í°ë³„ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë¶„ì„
        cursor.execute('''
            SELECT token_address, symbol, COUNT(*) as price_count,
                   MIN(block_number) as first_block, MAX(block_number) as last_block
            FROM historical_prices 
            WHERE block_number BETWEEN ? AND ?
            GROUP BY token_address
            ORDER BY price_count DESC
        ''', (start_block, end_block))
        
        coverage_stats = cursor.fetchall()
        
        logger.info("í† í°ë³„ ë°ì´í„° ì»¤ë²„ë¦¬ì§€:")
        for token_addr, symbol, count, first, last in coverage_stats[:10]:
            coverage_pct = (count / self.total_blocks) * 100
            logger.info(f"  {symbol}: {count:,} í¬ì¸íŠ¸ ({coverage_pct:.1f}% ì»¤ë²„ë¦¬ì§€)")
            
        # ë°ì´í„° ê°­ ì‹ë³„ ë° ë³´ê°„
        gap_filled_count = 0
        
        for token_addr, symbol, count, first, last in coverage_stats:
            if count < self.total_blocks * 0.1:  # 10% ë¯¸ë§Œ ì»¤ë²„ë¦¬ì§€ëŠ” ê±´ë„ˆëœ€
                continue
                
            # ë°ì´í„° ê°­ ì°¾ê¸°
            cursor.execute('''
                SELECT block_number, price_usd 
                FROM historical_prices 
                WHERE token_address = ? AND block_number BETWEEN ? AND ?
                ORDER BY block_number
            ''', (token_addr, start_block, end_block))
            
            price_points = cursor.fetchall()
            if len(price_points) < 2:
                continue
                
            # ê°„ë‹¨í•œ ì„ í˜• ë³´ê°„ìœ¼ë¡œ ê°­ ì±„ìš°ê¸°
            interpolated_points = []
            
            for i in range(len(price_points) - 1):
                current_block, current_price = price_points[i]
                next_block, next_price = price_points[i + 1]
                
                block_gap = next_block - current_block
                if block_gap > 100:  # 100 ë¸”ë¡ ì´ìƒ ê°­ì´ ìˆìœ¼ë©´ ë³´ê°„
                    price_diff = next_price - current_price
                    
                    for j in range(1, min(block_gap, 1000)):  # ìµœëŒ€ 1000ë¸”ë¡ê¹Œì§€ë§Œ
                        interp_block = current_block + j
                        interp_price = current_price + (price_diff * j / block_gap)
                        
                        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°íšŒ
                        cursor.execute('SELECT timestamp FROM blocks WHERE number = ?', (interp_block,))
                        timestamp_row = cursor.fetchone()
                        if timestamp_row:
                            interpolated_points.append((
                                token_addr, symbol, interp_price, timestamp_row[0], 
                                interp_block, 'interpolated', 0, 0
                            ))
                            
            # ë³´ê°„ëœ í¬ì¸íŠ¸ë“¤ ì €ì¥
            if interpolated_points:
                cursor.executemany('''
                    INSERT OR IGNORE INTO historical_prices 
                    (token_address, symbol, price_usd, timestamp, block_number, source, volume_24h, market_cap)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', interpolated_points)
                
                gap_filled_count += len(interpolated_points)
                
        conn.commit()
        conn.close()
        
        logger.info(f"ë°ì´í„° ë³´ê°„ ì™„ë£Œ: {gap_filled_count:,}ê°œ í¬ì¸íŠ¸ ì¶”ê°€")
        
    async def _generate_analysis_report(self, start_block: int, end_block: int):
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì „ì²´ í†µê³„
        cursor.execute('''
            SELECT COUNT(*) as total_records,
                   COUNT(DISTINCT token_address) as unique_tokens,
                   COUNT(DISTINCT block_number) as covered_blocks,
                   MIN(timestamp) as start_time,
                   MAX(timestamp) as end_time
            FROM historical_prices
            WHERE block_number BETWEEN ? AND ?
        ''', (start_block, end_block))
        
        stats = cursor.fetchone()
        total_records, unique_tokens, covered_blocks, start_time, end_time = stats
        
        # ê¸°ê°„ ê³„ì‚°
        duration_days = (end_time - start_time) / (24 * 3600)
        coverage_pct = (covered_blocks / self.total_blocks) * 100
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š ê³¼ê±° ë°ì´í„° ë°±í•„ë§ ë¶„ì„ ë¦¬í¬íŠ¸")
        logger.info("=" * 60)
        logger.info(f"ë¶„ì„ ê¸°ê°„: {duration_days:.1f}ì¼")
        logger.info(f"ë¸”ë¡ ë²”ìœ„: {start_block:,} ~ {end_block:,}")
        logger.info(f"ì´ ê°€ê²© ë ˆì½”ë“œ: {total_records:,}ê°œ")
        logger.info(f"ì»¤ë²„ëœ í† í° ìˆ˜: {unique_tokens}ê°œ")
        logger.info(f"ì»¤ë²„ëœ ë¸”ë¡ ìˆ˜: {covered_blocks:,}ê°œ ({coverage_pct:.1f}%)")
        
        # í† í°ë³„ ìƒìœ„ í†µê³„
        cursor.execute('''
            SELECT symbol, COUNT(*) as records, 
                   MIN(price_usd) as min_price, 
                   MAX(price_usd) as max_price,
                   AVG(price_usd) as avg_price
            FROM historical_prices 
            WHERE block_number BETWEEN ? AND ?
            GROUP BY token_address, symbol
            ORDER BY records DESC
            LIMIT 10
        ''', (start_block, end_block))
        
        top_tokens = cursor.fetchall()
        
        logger.info("\nìƒìœ„ í† í° í†µê³„:")
        for symbol, records, min_price, max_price, avg_price in top_tokens:
            price_range = ((max_price - min_price) / min_price) * 100 if min_price > 0 else 0
            logger.info(f"  {symbol}: {records:,} ë ˆì½”ë“œ, "
                       f"ê°€ê²© ë²”ìœ„: ${min_price:.6f} ~ ${max_price:.6f} "
                       f"({price_range:.1f}% ë³€ë™)")
        
        # ì¼ë³„ ë°ì´í„° ì»¤ë²„ë¦¬ì§€
        cursor.execute('''
            SELECT DATE(timestamp, 'unixepoch') as date, 
                   COUNT(DISTINCT token_address) as tokens_count,
                   COUNT(*) as total_records
            FROM historical_prices 
            WHERE block_number BETWEEN ? AND ?
            GROUP BY DATE(timestamp, 'unixepoch')
            ORDER BY date
            LIMIT 10
        ''', (start_block, end_block))
        
        daily_coverage = cursor.fetchall()
        
        if daily_coverage:
            logger.info("\nì¼ë³„ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ (ì²« 10ì¼):")
            for date, tokens, records in daily_coverage:
                logger.info(f"  {date}: {tokens}ê°œ í† í°, {records:,}ê°œ ë ˆì½”ë“œ")
                
        conn.close()
        
        # ì„±ê³µ ì§€í‘œ í™•ì¸
        paper_target_days = 150
        paper_target_tokens = 25
        
        success_criteria = {
            'duration': duration_days >= paper_target_days * 0.8,  # 80% of target duration
            'tokens': unique_tokens >= paper_target_tokens * 0.8,   # 80% of target tokens  
            'coverage': coverage_pct >= 50.0  # 50% block coverage
        }
        
        all_success = all(success_criteria.values())
        
        logger.info("\nğŸ“ˆ ë…¼ë¬¸ ì¬í˜„ ëª©í‘œ ë‹¬ì„±ë„:")
        logger.info(f"  ê¸°ê°„ ëª©í‘œ (150ì¼): {'âœ…' if success_criteria['duration'] else 'âŒ'} "
                   f"{duration_days:.1f}ì¼")
        logger.info(f"  í† í° ëª©í‘œ (25ê°œ): {'âœ…' if success_criteria['tokens'] else 'âŒ'} "
                   f"{unique_tokens}ê°œ")
        logger.info(f"  ì»¤ë²„ë¦¬ì§€ ëª©í‘œ: {'âœ…' if success_criteria['coverage'] else 'âŒ'} "
                   f"{coverage_pct:.1f}%")
        
        if all_success:
            logger.info("ğŸ‰ ê³¼ê±° ë°ì´í„° ë°±í•„ë§ ëª©í‘œ ë‹¬ì„±!")
        else:
            logger.warning("âš ï¸  ì¼ë¶€ ëª©í‘œê°€ ë¯¸ë‹¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤")
            
        return all_success
        
    async def get_historical_prices(self, token_address: str, start_block: int, 
                                  end_block: int) -> List[HistoricalPricePoint]:
        """íŠ¹ì • í† í°ì˜ ê³¼ê±° ê°€ê²© ë°ì´í„° ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT token_address, symbol, price_usd, timestamp, block_number, 
                       source, volume_24h, market_cap
                FROM historical_prices
                WHERE token_address = ? AND block_number BETWEEN ? AND ?
                ORDER BY block_number
            ''', (token_address.lower(), start_block, end_block))
            
            rows = cursor.fetchall()
            conn.close()
            
            return [
                HistoricalPricePoint(
                    token_address=row[0],
                    symbol=row[1],
                    price_usd=row[2],
                    timestamp=row[3],
                    block_number=row[4],
                    source=row[5],
                    volume_24h=row[6],
                    market_cap=row[7]
                )
                for row in rows
            ]
            
        except Exception as e:
            logger.error(f"ê³¼ê±° ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
            
    async def get_block_prices(self, block_number: int) -> Dict[str, HistoricalPricePoint]:
        """íŠ¹ì • ë¸”ë¡ì˜ ëª¨ë“  í† í° ê°€ê²© ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT token_address, symbol, price_usd, timestamp, block_number,
                       source, volume_24h, market_cap
                FROM historical_prices
                WHERE block_number = ?
            ''', (block_number,))
            
            rows = cursor.fetchall()
            conn.close()
            
            prices = {}
            for row in rows:
                price_point = HistoricalPricePoint(
                    token_address=row[0],
                    symbol=row[1],
                    price_usd=row[2],
                    timestamp=row[3],
                    block_number=row[4],
                    source=row[5],
                    volume_24h=row[6],
                    market_cap=row[7]
                )
                prices[row[0]] = price_point
                
            return prices
            
        except Exception as e:
            logger.error(f"ë¸”ë¡ ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    # í† í° ë§¤ë‹ˆì € ì´ˆê¸°í™”
    token_manager = TokenManager()
    
    # ê³¼ê±° ë°ì´í„° ë°±í•„ëŸ¬ ì´ˆê¸°í™”
    backfill = HistoricalDataBackfill(token_manager)
    
    # ìƒ˜í”Œ ê¸°ê°„ìœ¼ë¡œ ë°±í•„ë§ í…ŒìŠ¤íŠ¸ (1000 ë¸”ë¡)
    test_start = 9_100_000
    test_end = 9_101_000
    
    logger.info(f"í…ŒìŠ¤íŠ¸ ë°±í•„ë§ ì‹œì‘: ë¸”ë¡ {test_start} ~ {test_end}")
    await backfill.start_backfill(test_start, test_end)
    
    # ê²°ê³¼ í™•ì¸
    eth_address = token_manager.get_address_by_symbol('ETH')
    if eth_address:
        prices = await backfill.get_historical_prices(eth_address, test_start, test_end)
        logger.info(f"ETH ê°€ê²© ë°ì´í„° {len(prices)}ê°œ ìˆ˜ì§‘ë¨")

if __name__ == "__main__":
    asyncio.run(main())